&emsp;
# 画动态图


# 1 plot

```py
import random
import numpy as np
import matplotlib.pyplot as plt

def train(x:np.ndarray, y:np.ndarray, epochs=1000, lr=1e-2):

    k = 2 #random.random()
    b = 0

    plt.figure()
    axis_x = [x.min()-0.1, x.max()+0.1]
    axis_y = [y.min()-0.1, y.max()+0.1]
    for i in range(epochs):

        predict = k * x + b
        loss = np.sum((predict - y)** 2 * 0.5)

        delta_k = np.sum((y - predict) * (-x))
        delta_b = np.sum((y - predict) * (-1))

        k = k - lr * delta_k
        b = b - lr * delta_b

        tx = np.array(axis_x)
        ty = k * tx + b

        if (i + 1) % 100 == 0 or i < 3:
            #print("Iter %d : error=%f, k = %f, b = %f" % (i, err, k, b))
            plt.clf()
            plt.xlabel('x')
            plt.ylabel('y')
            plt.title("Iter %d : loss=%f, k = %f, b = %f" % (i, loss, k, b))
            plt.plot(x, y, ".")
            plt.plot(tx, ty, 'g-')
            plt.axis(axis_x+axis_y)
            plt.pause(0.5)

    return (k, b)


if __name__ == '__main__':
        
    #我们定义房价数据
    x = np.arange(10, dtype=np.float32).reshape(10, 1) + 2010
    y = np.array([[1.8, 2.1, 2.3, 2.3, 2.85, 3.0, 3.3, 4.9, 5.45, 5.0]], dtype=np.float32).T

    #数据归一化
    x_mean = x.mean()
    y_mean = y.mean()
    x_std  = x.std()
    y_std  = y.std()
    
    x = (x - x_mean) / x_std
    y = (y - y_mean) / y_std

    #梯度下降法求解
    k, b = train(x, y)

    #估算2019年的房价多少
    #归一化
    x_2019 = (2019 - x_mean) / x_std
    y_2019 = x_2019 * k + b

    #结果反归一化
    y_2019 = y_2019 * y_std + y_mean
    print("模型的参数是: k=%f, b=%f, 预估的2019房价为: %f 万元" % (k, b, y_2019))
```



&emsp;
# 2 animation
>Gradient Descent
```py
import time
import numpy as np
import matplotlib.pyplot as plt

from matplotlib.animation import FuncAnimation
from mpl_toolkits.axisartist.axislines import AxesZero


# Define the functions for f(x) and its gradient
def fx(x):
    return 3*x**2 + 6*x + 5

def fx_gd(x):
    return 6*x + 6

def line(x, y, k):
    b = y - k*x
    p1_x = 5
    p1_y = k*p1_x + b
    p2_y = 0
    p2_x = -b/(k+1e-5)
    
    return [p1_x, p2_x], [p1_y, p2_y]

# Define a function that updates the plot with the current x and y values
def update_plot(i):
    global x, y
    gradient = fx_gd(x)
    x_new = x - lr * gradient
    y_new = fx(x_new)
    ax.clear()
    for direction in ['xzero', 'yzero']:
        ax.axis[direction].set_axisline_style("-|>")
        ax.axis[direction].set_visible(True)
    for direction in ['left', 'right', 'bottom', 'top']:
        ax.axis[direction].set_visible(False)
        
    ax.set_xlim((-5, 5))
    ax.plot(xticks, f)
    ax.plot(x, y, marker='o')
    
    line_x, line_y = line(x_new, y_new, gradient)
    ax.plot(line_x, line_y)
    
    x_change = abs(x_new - x)
    if x_change < tolerance:
        ani.event_source.stop()
        print(f"Stopped after {i} iterations")
        exit()

    x = x_new
    y = y_new
    print(f"Iteration: {i}, Currently x={x:.4f}, y={y:.4f}, error: {x_change}")
    time.sleep(0.1)

if __name__ == '__main__':
    # Create the figure and the axes
    fig = plt.figure()
    ax = fig.add_subplot(axes_class=AxesZero)

    # Set the x-axis limits and create the x-values for the function
    xticks = np.linspace(-5, 5, 100)
    f = fx(xticks) # Create the function values for the x-axis values
    x = 5          # Set the initial value of x
    y = fx(x)      # Set the initial value of y

    lr = 0.01        # Set the learning rate
    epochs = 1000    # Set the maximum number of iterations
    tolerance = 1e-4 # Set the tolerance level for convergence

    # Create a FuncAnimation object to animate the plot
    ani = FuncAnimation(fig, update_plot, frames=epochs, interval=50)

    # Show the plot
    plt.grid()
    plt.show()
```


